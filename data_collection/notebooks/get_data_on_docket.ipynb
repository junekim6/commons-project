{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the comments on a single docket\n",
    "\n",
    "This notebook allows you to collect the data and metadata on all the comments on a single docket from the Regulations.gov API. It also extracts the text from comments submitted as PDFs and structure the data into a CSV file with the comments and metadata.\n",
    "\n",
    "We might already have collected the comments on the docket you are looking for. In that case, you can search for the docket on [www.commons-project.com/dockets](https://www.commons-project.com/dockets).\n",
    "\n",
    "- Mention bulk download of comments from Regulations.gov API and the use and limitations on that!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `docket_id`\n",
    "\n",
    "You can find the exact docket ID on [regulations.gov](https://www.regulations.gov/).\n",
    "\n",
    "Example:\n",
    "\n",
    "```bash\n",
    "docket_id = \"EPA-HQ-OLEM-2023-0278\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_id = \"EPA-HQ-OLEM-2023-0278\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Load in the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, timedelta\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import pdfplumber\n",
    "import psycopg2\n",
    "import PyPDF2\n",
    "import pytz\n",
    "import requests\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTChar, LTTextContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys\n",
    "\n",
    "Before you can run this notebook, you need to get an API key from regulations.gov. You can get one by going to https://open.gsa.gov/api/regulationsgov/ and clicking on the \"Get API Key\" button. Once you have the key, you can load it into the `.env` file.\n",
    "\n",
    "```bash\n",
    "echo \"REGULATIONS_GOV_API_KEY=your-key-here\" > .env\n",
    "```\n",
    "\n",
    "Load in the regulations.gov API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"REGGOV_API_KEY\")\n",
    "extra_api_key = os.getenv(\"REGGOV_API_KEY_N1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect the comments\n",
    "\n",
    "### 2.1 Get all the comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems like there are less than 250 comments in this docket.\n"
     ]
    }
   ],
   "source": [
    "comment_ids = []\n",
    "for page in range(1, 20):\n",
    "    url = f\"https://api.regulations.gov/v4/comments?filter[docketId]={docket_id}&page[size]=250&page[number]={page}&sort=lastModifiedDate&api_key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    result = response.json()\n",
    "    for item in result[\"data\"]:\n",
    "        comment_ids.append(item['id'])\n",
    "\n",
    "api_response = []\n",
    "\n",
    "if result[\"data\"] is None or not result[\"data\"]:\n",
    "    print(\"Seems like there are less than 250 comments in this docket.\")\n",
    "else:\n",
    "    api_response.append(result)\n",
    "\n",
    "# If there are more than 250 comments, we need to make additional API calls to get all the comments\n",
    "if result['meta']['totalElements'] > 250:\n",
    "\n",
    "    # Reset the time variables to get the last modified date of the last comment in the first API call. Thus we can use this date to get the next batch of comments\n",
    "    greater_than = api_response[-1][\"data\"][-1][\"attributes\"][\"lastModifiedDate\"][:-1]\n",
    "    greater_than = greater_than.replace(\"T\", \" \")\n",
    "    date_str = greater_than\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    date_obj = datetime.strptime(date_str, date_format)\n",
    "    greater_than = date_obj - timedelta(\n",
    "        hours=5\n",
    "    )\n",
    "\n",
    "    for page in range(1, 20):\n",
    "        url = f\"https://api.regulations.gov/v4/comments?filter[docketId]={docket_id}&filter[lastModifiedDate][ge]={greater_than}&page[size]=250&page[number]={page}&sort=lastModifiedDate&api_key={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        result = response.json()\n",
    "        for item in result[\"data\"]:\n",
    "            comment_ids.append(item['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected the IDs for 102 comments\n"
     ]
    }
   ],
   "source": [
    "print(f\"Collected the IDs for {len(comment_ids)} comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get the metadata for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"J1\", \"J2\", \"J3\", \"J4\", \"J5\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how many rounds it will take to scrape all the comments\n",
    "rounds = len(comment_ids) / 500\n",
    "rounds = math.ceil(rounds)\n",
    "\n",
    "comment_details = []\n",
    "\n",
    "# We scrape the comments using their index number in the ids list\n",
    "num = 0\n",
    "\n",
    "for round in range(rounds):\n",
    "    for key in keys:\n",
    "        api_key = os.getenv(f\"REGGOV_API_KEY_{key}\")\n",
    "        for i in range(50):\n",
    "            # In the last round, there might not be 50 comments left, so we break when we run out of comments to scrape\n",
    "            try:\n",
    "                comment_id = comment_ids[num]\n",
    "                docket_id = comment_id[:-5]\n",
    "                url = f\"https://api.regulations.gov/v4/comments/{comment_id}?include=attachments&api_key={api_key}\"\n",
    "                response = requests.get(url)\n",
    "                result = response.json()\n",
    "\n",
    "                # And append the data to the today_comments list so we can access the download links and store the pdfs\n",
    "                comment_details.append(result)\n",
    "            \n",
    "            except Exception as e:\n",
    "                    break\n",
    "\n",
    "            num = num + 1\n",
    "\n",
    "            # Sleep for 0.4 seconds to avoid hitting the API rate limit\n",
    "            time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract the text from comments stored as PDFs\n",
    "Extract the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_text(comments):\n",
    "\n",
    "    # Function to extract text\n",
    "    def text_extraction(element):\n",
    "        # Extracting the text from the in-line text element\n",
    "        line_text = element.get_text()\n",
    "\n",
    "        # Find the formats of the text\n",
    "        # Initialize the list with all the formats that appeared in the line of text\n",
    "        line_formats = []\n",
    "        for text_line in element:\n",
    "            if isinstance(text_line, LTTextContainer):\n",
    "                # Iterating through each character in the line of text\n",
    "                for character in text_line:\n",
    "                    if isinstance(character, LTChar):\n",
    "                        # Append the font name of the character\n",
    "                        line_formats.append(character.fontname)\n",
    "                        # Append the font size of the character\n",
    "                        line_formats.append(character.size)\n",
    "        # Find the unique font sizes and names in the line\n",
    "        format_per_line = list(set(line_formats))\n",
    "\n",
    "        # Return a tuple with the text in each line along with its format\n",
    "        return (line_text, format_per_line)\n",
    "\n",
    "    # Loop through the comments and extract the text from the attached pdfs\n",
    "    for comment in comments:\n",
    "        id = comment[\"data\"][\"id\"]\n",
    "        try:\n",
    "            num = 1\n",
    "            attachment_url = \"\"\n",
    "            for files in comment[\"included\"]:\n",
    "                result = \"\"\n",
    "                # Loop through the files and get the pdfs if they exist\n",
    "                if files[\"attributes\"][\"fileFormats\"] is not None:\n",
    "                    for file in files[\"attributes\"][\"fileFormats\"]:\n",
    "                        try:\n",
    "                            url = file[\"fileUrl\"]\n",
    "                            response = requests.get(url)\n",
    "                            attachment_url = attachment_url + str(url) + \" \"\n",
    "\n",
    "                            # pdf_path = f\"{id}_attachment_{num}.pdf\"\n",
    "                            pdf_path = os.path.abspath(f\"{id}_attachment_{num}.pdf\")\n",
    "                            doc_path = os.path.abspath(\"temp.docx\")\n",
    "                            soffice_path = (\n",
    "                                \"/Applications/LibreOffice.app/Contents/MacOS/soffice\"\n",
    "                            )\n",
    "\n",
    "                            if url.endswith(\".docx\"):\n",
    "                                with open(doc_path, \"wb\") as f:\n",
    "                                    f.write(response.content)\n",
    "                                subprocess.run(\n",
    "                                    [\n",
    "                                        soffice_path,\n",
    "                                        \"--convert-to\",\n",
    "                                        \"pdf\",\n",
    "                                        \"--headless\",\n",
    "                                        doc_path,\n",
    "                                    ]\n",
    "                                )\n",
    "                                os.rename(\"temp.pdf\", pdf_path)\n",
    "                                os.remove(\"temp.docx\")\n",
    "\n",
    "                            else:\n",
    "                                with open(pdf_path, \"wb\") as f:\n",
    "                                    f.write(response.content)\n",
    "\n",
    "                            # ADD PDF SCRAPER HERE\n",
    "                            pdfFileObj = open(pdf_path, \"rb\")\n",
    "                            pdfReaded = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "                            # Get the number of pages in the PDF file\n",
    "                            num_pages = len(pdfReaded.pages)\n",
    "\n",
    "                            # Create the dictionary to extract text from each image\n",
    "                            text_per_page = {}\n",
    "\n",
    "                            # We extract the pages from the PDF\n",
    "                            for pagenum, page in enumerate(extract_pages(pdf_path)):\n",
    "                                if pagenum > 2:\n",
    "                                    break\n",
    "                                # Initialize the variables needed for the text extraction from the page\n",
    "                                pageObj = pdfReaded.pages[pagenum]\n",
    "                                page_text = []\n",
    "                                line_format = []\n",
    "                                page_content = []\n",
    "\n",
    "                                # Open the pdf file\n",
    "                                pdf = pdfplumber.open(pdf_path)\n",
    "\n",
    "                                # Find the examined page\n",
    "                                page_tables = pdf.pages[pagenum]\n",
    "\n",
    "                                # Find all the elements\n",
    "                                page_elements = [\n",
    "                                    (element.y1, element) for element in page._objs\n",
    "                                ]\n",
    "\n",
    "                                # Sort all the elements as they appear in the page\n",
    "                                page_elements.sort(key=lambda a: a[0], reverse=True)\n",
    "\n",
    "                                # Find the elements that composed a page\n",
    "                                for i, component in enumerate(page_elements):\n",
    "                                    # Extract the position of the top side of the element in the PDF\n",
    "                                    pos = component[0]\n",
    "\n",
    "                                    # Extract the element of the page layout\n",
    "                                    element = component[1]\n",
    "\n",
    "                                    # Check if the element is a text element\n",
    "                                    if isinstance(element, LTTextContainer):\n",
    "                                        # Use the function to extract the text and format for each text element\n",
    "                                        (line_text, format_per_line) = text_extraction(\n",
    "                                            element\n",
    "                                        )\n",
    "\n",
    "                                        # Append the text of each line to the page text\n",
    "                                        page_text.append(line_text)\n",
    "\n",
    "                                        # Append the format for each line containing text\n",
    "                                        line_format.append(format_per_line)\n",
    "                                        page_content.append(line_text)\n",
    "                                    # Create the key of the dictionary\n",
    "                                    dctkey = \"Page_\" + str(pagenum)\n",
    "\n",
    "                                    # Add the list of list as the value of the page key\n",
    "                                    text_per_page[dctkey] = [\n",
    "                                        page_text,\n",
    "                                        line_format,\n",
    "                                        page_content,\n",
    "                                    ]\n",
    "\n",
    "                                # Display the content of the page\n",
    "                                page_result = \"\".join(\n",
    "                                    text_per_page[\"Page_\" + str(pagenum)][0]\n",
    "                                )\n",
    "                                result = result + \"\\n \\n\" + page_result\n",
    "\n",
    "                                # Close the pdf file\n",
    "                                pdfFileObj.close()\n",
    "\n",
    "                                # Remove pdf files that are not needed anymore\n",
    "                            try:\n",
    "                                os.remove(pdf_path)\n",
    "                                files = glob(f\"*.pdf\")\n",
    "                                for f in files:\n",
    "                                    os.remove(f)\n",
    "                            except:\n",
    "                                print(\"No files to remove\")\n",
    "\n",
    "                            num = num + 1\n",
    "\n",
    "                            # Save the extracted text to the json file from the api call\n",
    "                            comment[\"data\"][\"attributes\"][\"pdf_extracted_text\"] = result\n",
    "                            comment[\"data\"][\"attributes\"][\n",
    "                                \"attachment_read\"\n",
    "                            ] = \"attachment extracted\"\n",
    "                            comment[\"data\"][\"attributes\"][\"attachments_url\"] = attachment_url\n",
    "\n",
    "                        except Exception as inst:\n",
    "                            print(type(inst))  # the exception type\n",
    "                            x = inst.args  # unpack args\n",
    "                            print(\"x =\", x)\n",
    "                            comment[\"data\"][\"attributes\"][\n",
    "                                \"attachment_read\"\n",
    "                            ] = \"attachment failed\"\n",
    "                            comment[\"data\"][\"attributes\"][\"attachments_url\"] = attachment_url\n",
    "                        except:\n",
    "                            comment[\"data\"][\"attributes\"][\n",
    "                                \"attachment_read\"\n",
    "                            ] = \"attachment failed\"\n",
    "                            comment[\"data\"][\"attributes\"][\"attachments_url\"] = attachment_url\n",
    "                            raise\n",
    "                else:\n",
    "                    comment[\"data\"][\"attributes\"][\"attachment_read\"] = \"no attachment\"\n",
    "                    comment[\"data\"][\"attributes\"][\"attachments_url\"] = None\n",
    "        except KeyError:\n",
    "            comment[\"data\"][\"attributes\"][\"attachment_read\"] = \"no attachment\"\n",
    "            comment[\"data\"][\"attributes\"][\"attachments_url\"] = None\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the pdf extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_comment_text(comment_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reshape and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_data(data, keys_to_include):\n",
    "    final_data = []\n",
    "    for comment in data:\n",
    "        # Flatten the nested dictionaries\n",
    "        flat_comment = flatten(comment)\n",
    "        result_dict = {}\n",
    "        for key, value in flat_comment.items():\n",
    "            if key in keys_to_include:\n",
    "                if isinstance(value, dict):\n",
    "                    # Recursively process nested dictionaries\n",
    "                    result_dict[key] = structure_data(value, keys_to_include)\n",
    "                else:\n",
    "                    # Include non-dictionary values\n",
    "                    result_dict[key] = value if value is not None else \"\"\n",
    "        final_data.append(result_dict)\n",
    "\n",
    "    # Rename the keys to match the database\n",
    "    key_mapping = {\n",
    "        \"data_id\": \"comment_id\",\n",
    "        \"data_attributes_commentOnDocumentId\": \"document_id\",\n",
    "        \"data_attributes_docketId\": \"docket_id\",\n",
    "        \"data_attributes_agencyId\": \"agency_id\",\n",
    "        \"data_attributes_title\": \"title\",\n",
    "        \"data_attributes_comment\": \"comment\",\n",
    "        \"data_attributes_pdf_extracted_text\": \"comment_pdf_extracted\",\n",
    "        \"data_attributes_firstName\": \"commenter_first_name\",\n",
    "        \"data_attributes_lastName\": \"commenter_last_name\",\n",
    "        \"data_attributes_organization\": \"commenter_organization\",\n",
    "        \"data_attributes_address1\": \"commenter_address1\",\n",
    "        \"data_attributes_address2\": \"commenter_address2\",\n",
    "        \"data_attributes_zip\": \"commenter_zip\",\n",
    "        \"data_attributes_city\": \"commenter_city\",\n",
    "        \"data_attributes_stateProvinceRegion\": \"commenter_state_province_region\",\n",
    "        \"data_attributes_country\": \"commenter_country\",\n",
    "        \"data_attributes_email\": \"commenter_email\",\n",
    "        \"data_attributes_receiveDate\": \"receive_date\",\n",
    "        \"data_attributes_postedDate\": \"posted_date\",\n",
    "        \"data_attributes_postmarkDate\": \"postmark_date\",\n",
    "        \"data_attributes_duplicateComments\": \"duplicate_comments\",\n",
    "        \"data_attributes_attachment_read\": \"attachment_read\",\n",
    "        \"data_attributes_attachments_url\": \"attachment_url\",\n",
    "        \"data_attributes_withdrawn\": \"withdrawn\",\n",
    "        \"data_links_self\": \"api_url\",\n",
    "    }\n",
    "\n",
    "    # Rename the keys so they match the database\n",
    "    for i in final_data:\n",
    "        for old_key, new_key in key_mapping.items():\n",
    "            i[new_key] = i.pop(old_key, \"\")\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:22:02.759 soffice[64942:5815807] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:22:13.221 soffice[64965:5816378] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:22:19.775 soffice[64973:5816552] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x146ee8 for key /Info\n",
      "Multiple definitions in dictionary at byte 0x146ef5 for key /Info\n",
      "Multiple definitions in dictionary at byte 0x146f02 for key /Info\n",
      "2024-04-24 13:22:26.331 soffice[64983:5816708] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:22:30.939 soffice[64987:5816776] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:22:35.803 soffice[64991:5816843] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.docx as a Writer document -> /Users/laurabejderjensen/Desktop/Github/commons-project/data_collection/notebooks/temp.pdf using filter : writer_pdf_Export\n",
      "<class 'KeyError'>\n",
      "x = ('Page_2',)\n"
     ]
    }
   ],
   "source": [
    "# Specify the keys to include in the resulting dictionary\n",
    "keys_to_include = [\n",
    "    \"data_id\",\n",
    "    \"data_attributes_commentOnDocumentId\",\n",
    "    \"data_attributes_docketId\",\n",
    "    \"data_attributes_agencyId\",\n",
    "    \"data_attributes_title\",\n",
    "    \"data_attributes_comment\",\n",
    "    \"data_attributes_pdf_extracted_text\",\n",
    "    \"data_attributes_firstName\",\n",
    "    \"data_attributes_lastName\",\n",
    "    \"data_attributes_organization\",\n",
    "    \"data_attributes_address1\",\n",
    "    \"data_attributes_address2\",\n",
    "    \"data_attributes_zip\",\n",
    "    \"data_attributes_city\",\n",
    "    \"data_attributes_country\",\n",
    "    \"data_attributes_stateProvinceRegion\",\n",
    "    \"data_attributes_email\",\n",
    "    \"data_attributes_receiveDate\",\n",
    "    \"data_attributes_postedDate\",\n",
    "    \"data_attributes_postmarkDate\",\n",
    "    \"data_links_self\",\n",
    "    \"data_attributes_attachments_url\",\n",
    "    \"data_attributes_attachment_read\",\n",
    "    \"data_attributes_duplicateComments\",\n",
    "    \"data_attributes_withdrawn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the nested JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = structure_data(full_data, keys_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(input_string):\n",
    "    \"\"\"Remove NULL characters from a string.\"\"\"\n",
    "    if input_string is not None:\n",
    "        # clean up html - list all the html characters that need to be changed and what they should be changed to\n",
    "        html_chars = {\n",
    "            \"&amp;\": \"&\",\n",
    "            \"&gt;\": \">\",\n",
    "            \"&lt;\": \"<\",\n",
    "            \"&nbsp;\": \" \",\n",
    "            \"&quot;\": '\"',\n",
    "            \"&#39;\": \"'\",\n",
    "            \"&#34;\": '\"',\n",
    "            \"nan\": \"\",\n",
    "            \"<br>\": \" \",\n",
    "            \"<br/>\": \" \",\n",
    "            \"\\n\": \" \",\n",
    "            \"\\x00\": \"\",\n",
    "        }\n",
    "        for key, value in html_chars.items():\n",
    "            input_string = input_string.replace(key, value)\n",
    "\n",
    "        input_string = input_string.replace(\"See Attached\", \"\")\n",
    "        input_string = input_string.replace(\"See attached file(s)\", \"\")\n",
    "        input_string = html.unescape(input_string)\n",
    "\n",
    "    return input_string\n",
    "\n",
    "\n",
    "# CREATE THE FULL TEXT AND CLEAN_TEXT COLUMNS:\n",
    "for item in result:\n",
    "    # Create a new column that combines the comment and the extracted text from the pdf\n",
    "    item[\"full_text\"] = item[\"comment\"] + \" \" + item[\"comment_pdf_extracted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Structure the data into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>docket_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_pdf_extracted</th>\n",
       "      <th>commenter_first_name</th>\n",
       "      <th>commenter_last_name</th>\n",
       "      <th>commenter_organization</th>\n",
       "      <th>...</th>\n",
       "      <th>commenter_email</th>\n",
       "      <th>receive_date</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>postmark_date</th>\n",
       "      <th>duplicate_comments</th>\n",
       "      <th>attachment_read</th>\n",
       "      <th>attachment_url</th>\n",
       "      <th>withdrawn</th>\n",
       "      <th>api_url</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0183</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Anonymous public comment</td>\n",
       "      <td>I strongly support and encourage the addition ...</td>\n",
       "      <td>\\n \\nNTP\\nNational Toxicology Program\\nU.S. De...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-10T05:00:00Z</td>\n",
       "      <td>2024-02-13T05:00:00Z</td>\n",
       "      <td>2024-02-10T05:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>attachment extracted</td>\n",
       "      <td>https://downloads.regulations.gov/EPA-HQ-OLEM-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>I strongly support and encourage the addition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0180</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Anonymous public comment</td>\n",
       "      <td>My company is small (appx. 180 employees) and ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-08T05:00:00Z</td>\n",
       "      <td>2024-02-09T05:00:00Z</td>\n",
       "      <td>2024-02-08T05:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>no attachment</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>My company is small (appx. 180 employees) and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0182</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Comment submitted by Bernard Wlodarski</td>\n",
       "      <td>it&amp;#39;s about time these chemicals were banne...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-09T05:00:00Z</td>\n",
       "      <td>2024-02-09T05:00:00Z</td>\n",
       "      <td>2024-02-09T05:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>no attachment</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>it&amp;#39;s about time these chemicals were banne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0181</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Comment submitted by Delaney Moran</td>\n",
       "      <td>This law proposes the addition of nine Per- an...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-08T05:00:00Z</td>\n",
       "      <td>2024-02-09T05:00:00Z</td>\n",
       "      <td>2024-02-08T05:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>no attachment</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>This law proposes the addition of nine Per- an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0184</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Anonymous public comment</td>\n",
       "      <td>PFAS must be included in the List of Hazardous...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-11T05:00:00Z</td>\n",
       "      <td>2024-02-15T05:00:00Z</td>\n",
       "      <td>2024-02-11T05:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>no attachment</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>PFAS must be included in the List of Hazardous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0286</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Comment submitted by State of Utah Division of...</td>\n",
       "      <td>See Attached</td>\n",
       "      <td>\\n \\nDepartment of\\nEnvironmental Quality\\nKim...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-02T04:00:00Z</td>\n",
       "      <td>2024-04-12T04:00:00Z</td>\n",
       "      <td>2024-03-21T04:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>attachment extracted</td>\n",
       "      <td>https://downloads.regulations.gov/EPA-HQ-OLEM-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>See Attached \\n \\nDepartment of\\nEnvironmental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0288</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Mass Comment Campaign sponsored by U.S. PIRG (...</td>\n",
       "      <td>&lt;br/&gt;&lt;br/&gt;Re: Listing of Specific Per- and Pol...</td>\n",
       "      <td>\\n \\nFirst Name\\nLast Name\\nCity\\nState\\nZIP C...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>2024-04-15T04:00:00Z</td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>10510</td>\n",
       "      <td>attachment extracted</td>\n",
       "      <td>https://downloads.regulations.gov/EPA-HQ-OLEM-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>&lt;br/&gt;&lt;br/&gt;Re: Listing of Specific Per- and Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0287</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Mass Comment Campaign sponsoring organization ...</td>\n",
       "      <td>I&amp;rsquo;m writing to support the U.S. Environm...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-27T04:00:00Z</td>\n",
       "      <td>2024-04-15T04:00:00Z</td>\n",
       "      <td>2024-03-27T04:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>no attachment</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>I&amp;rsquo;m writing to support the U.S. Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0290</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Comment submitted by National PFAS Contaminati...</td>\n",
       "      <td>Please find the attached appendices containing...</td>\n",
       "      <td>\\n \\nAnn Occup Environ Med. 2023 Mar 15;35:e5\\...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>2024-04-15T04:00:00Z</td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>attachment extracted</td>\n",
       "      <td>https://downloads.regulations.gov/EPA-HQ-OLEM-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>Please find the attached appendices containing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0289</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278-0001</td>\n",
       "      <td>EPA-HQ-OLEM-2023-0278</td>\n",
       "      <td>EPA</td>\n",
       "      <td>Comment submitted by National PFAS Contaminati...</td>\n",
       "      <td>Please find the attached appendices containing...</td>\n",
       "      <td>\\n \\nJ,,_.,,_ Public Employees for \\n~ Environ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>2024-04-15T04:00:00Z</td>\n",
       "      <td>2024-04-08T04:00:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>attachment extracted</td>\n",
       "      <td>https://downloads.regulations.gov/EPA-HQ-OLEM-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.regulations.gov/v4/comments/EPA-HQ...</td>\n",
       "      <td>Please find the attached appendices containing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     comment_id                 document_id  \\\n",
       "0    EPA-HQ-OLEM-2023-0278-0183  EPA-HQ-OLEM-2023-0278-0001   \n",
       "1    EPA-HQ-OLEM-2023-0278-0180  EPA-HQ-OLEM-2023-0278-0001   \n",
       "2    EPA-HQ-OLEM-2023-0278-0182  EPA-HQ-OLEM-2023-0278-0001   \n",
       "3    EPA-HQ-OLEM-2023-0278-0181  EPA-HQ-OLEM-2023-0278-0001   \n",
       "4    EPA-HQ-OLEM-2023-0278-0184  EPA-HQ-OLEM-2023-0278-0001   \n",
       "..                          ...                         ...   \n",
       "97   EPA-HQ-OLEM-2023-0278-0286  EPA-HQ-OLEM-2023-0278-0001   \n",
       "98   EPA-HQ-OLEM-2023-0278-0288  EPA-HQ-OLEM-2023-0278-0001   \n",
       "99   EPA-HQ-OLEM-2023-0278-0287  EPA-HQ-OLEM-2023-0278-0001   \n",
       "100  EPA-HQ-OLEM-2023-0278-0290  EPA-HQ-OLEM-2023-0278-0001   \n",
       "101  EPA-HQ-OLEM-2023-0278-0289  EPA-HQ-OLEM-2023-0278-0001   \n",
       "\n",
       "                 docket_id agency_id  \\\n",
       "0    EPA-HQ-OLEM-2023-0278       EPA   \n",
       "1    EPA-HQ-OLEM-2023-0278       EPA   \n",
       "2    EPA-HQ-OLEM-2023-0278       EPA   \n",
       "3    EPA-HQ-OLEM-2023-0278       EPA   \n",
       "4    EPA-HQ-OLEM-2023-0278       EPA   \n",
       "..                     ...       ...   \n",
       "97   EPA-HQ-OLEM-2023-0278       EPA   \n",
       "98   EPA-HQ-OLEM-2023-0278       EPA   \n",
       "99   EPA-HQ-OLEM-2023-0278       EPA   \n",
       "100  EPA-HQ-OLEM-2023-0278       EPA   \n",
       "101  EPA-HQ-OLEM-2023-0278       EPA   \n",
       "\n",
       "                                                 title  \\\n",
       "0                             Anonymous public comment   \n",
       "1                             Anonymous public comment   \n",
       "2               Comment submitted by Bernard Wlodarski   \n",
       "3                   Comment submitted by Delaney Moran   \n",
       "4                             Anonymous public comment   \n",
       "..                                                 ...   \n",
       "97   Comment submitted by State of Utah Division of...   \n",
       "98   Mass Comment Campaign sponsored by U.S. PIRG (...   \n",
       "99   Mass Comment Campaign sponsoring organization ...   \n",
       "100  Comment submitted by National PFAS Contaminati...   \n",
       "101  Comment submitted by National PFAS Contaminati...   \n",
       "\n",
       "                                               comment  \\\n",
       "0    I strongly support and encourage the addition ...   \n",
       "1    My company is small (appx. 180 employees) and ...   \n",
       "2    it&#39;s about time these chemicals were banne...   \n",
       "3    This law proposes the addition of nine Per- an...   \n",
       "4    PFAS must be included in the List of Hazardous...   \n",
       "..                                                 ...   \n",
       "97                                        See Attached   \n",
       "98   <br/><br/>Re: Listing of Specific Per- and Pol...   \n",
       "99   I&rsquo;m writing to support the U.S. Environm...   \n",
       "100  Please find the attached appendices containing...   \n",
       "101  Please find the attached appendices containing...   \n",
       "\n",
       "                                 comment_pdf_extracted commenter_first_name  \\\n",
       "0    \\n \\nNTP\\nNational Toxicology Program\\nU.S. De...                        \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "..                                                 ...                  ...   \n",
       "97   \\n \\nDepartment of\\nEnvironmental Quality\\nKim...                        \n",
       "98   \\n \\nFirst Name\\nLast Name\\nCity\\nState\\nZIP C...                        \n",
       "99                                                                            \n",
       "100  \\n \\nAnn Occup Environ Med. 2023 Mar 15;35:e5\\...                        \n",
       "101  \\n \\nJ,,_.,,_ Public Employees for \\n~ Environ...                        \n",
       "\n",
       "    commenter_last_name commenter_organization  ... commenter_email  \\\n",
       "0                                               ...                   \n",
       "1                                               ...                   \n",
       "2                                               ...                   \n",
       "3                                               ...                   \n",
       "4                                               ...                   \n",
       "..                  ...                    ...  ...             ...   \n",
       "97                                              ...                   \n",
       "98                                              ...                   \n",
       "99                                              ...                   \n",
       "100                                             ...                   \n",
       "101                                             ...                   \n",
       "\n",
       "             receive_date           posted_date         postmark_date  \\\n",
       "0    2024-02-10T05:00:00Z  2024-02-13T05:00:00Z  2024-02-10T05:00:00Z   \n",
       "1    2024-02-08T05:00:00Z  2024-02-09T05:00:00Z  2024-02-08T05:00:00Z   \n",
       "2    2024-02-09T05:00:00Z  2024-02-09T05:00:00Z  2024-02-09T05:00:00Z   \n",
       "3    2024-02-08T05:00:00Z  2024-02-09T05:00:00Z  2024-02-08T05:00:00Z   \n",
       "4    2024-02-11T05:00:00Z  2024-02-15T05:00:00Z  2024-02-11T05:00:00Z   \n",
       "..                    ...                   ...                   ...   \n",
       "97   2024-04-02T04:00:00Z  2024-04-12T04:00:00Z  2024-03-21T04:00:00Z   \n",
       "98   2024-04-08T04:00:00Z  2024-04-15T04:00:00Z  2024-04-08T04:00:00Z   \n",
       "99   2024-03-27T04:00:00Z  2024-04-15T04:00:00Z  2024-03-27T04:00:00Z   \n",
       "100  2024-04-08T04:00:00Z  2024-04-15T04:00:00Z  2024-04-08T04:00:00Z   \n",
       "101  2024-04-08T04:00:00Z  2024-04-15T04:00:00Z  2024-04-08T04:00:00Z   \n",
       "\n",
       "    duplicate_comments       attachment_read  \\\n",
       "0                    1  attachment extracted   \n",
       "1                    1         no attachment   \n",
       "2                    1         no attachment   \n",
       "3                    1         no attachment   \n",
       "4                    1         no attachment   \n",
       "..                 ...                   ...   \n",
       "97                   1  attachment extracted   \n",
       "98               10510  attachment extracted   \n",
       "99                   1         no attachment   \n",
       "100                  1  attachment extracted   \n",
       "101                  1  attachment extracted   \n",
       "\n",
       "                                        attachment_url withdrawn  \\\n",
       "0    https://downloads.regulations.gov/EPA-HQ-OLEM-...     False   \n",
       "1                                                          False   \n",
       "2                                                          False   \n",
       "3                                                          False   \n",
       "4                                                          False   \n",
       "..                                                 ...       ...   \n",
       "97   https://downloads.regulations.gov/EPA-HQ-OLEM-...     False   \n",
       "98   https://downloads.regulations.gov/EPA-HQ-OLEM-...     False   \n",
       "99                                                         False   \n",
       "100  https://downloads.regulations.gov/EPA-HQ-OLEM-...     False   \n",
       "101  https://downloads.regulations.gov/EPA-HQ-OLEM-...     False   \n",
       "\n",
       "                                               api_url  \\\n",
       "0    https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "1    https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "2    https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "3    https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "4    https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "..                                                 ...   \n",
       "97   https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "98   https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "99   https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "100  https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "101  https://api.regulations.gov/v4/comments/EPA-HQ...   \n",
       "\n",
       "                                             full_text  \n",
       "0    I strongly support and encourage the addition ...  \n",
       "1    My company is small (appx. 180 employees) and ...  \n",
       "2    it&#39;s about time these chemicals were banne...  \n",
       "3    This law proposes the addition of nine Per- an...  \n",
       "4    PFAS must be included in the List of Hazardous...  \n",
       "..                                                 ...  \n",
       "97   See Attached \\n \\nDepartment of\\nEnvironmental...  \n",
       "98   <br/><br/>Re: Listing of Specific Per- and Pol...  \n",
       "99   I&rsquo;m writing to support the U.S. Environm...  \n",
       "100  Please find the attached appendices containing...  \n",
       "101  Please find the attached appendices containing...  \n",
       "\n",
       "[102 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(f\"{docket_id}_comments.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
